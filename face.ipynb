{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fc99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cyber-Tech\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Face & Emotion Detection System Initialized\n",
      "Available emotions for detection: angry, disgust, fear, happy, sad, surprise, neutral\n",
      "Face Emotion Detection Tool - Jupyter Mode\n",
      "\n",
      "Choose an option:\n",
      "1. Run webcam detection\n",
      "2. Select an image file\n",
      "Invalid choice\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "class FaceEmotionDetection:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the face and emotion detection system\"\"\"\n",
    "        # Initialize face detection\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.emotions = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "\n",
    "        # Print initialization message\n",
    "        print(\"Face & Emotion Detection System Initialized\")\n",
    "        print(\"Available emotions for detection:\", \", \".join(self.emotions))\n",
    "\n",
    "    def detect_faces_emotions(self, image):\n",
    "        \"\"\"\n",
    "        Detect faces and emotions in an image\n",
    "\n",
    "        Parameters:\n",
    "        - image: Input image (numpy array)\n",
    "\n",
    "        Returns:\n",
    "        - processed_image: Image with detection results drawn\n",
    "        - results: List of dictionaries containing face locations and emotions\n",
    "        \"\"\"\n",
    "        # Create a copy of the image to draw on\n",
    "        processed_image = image.copy()\n",
    "\n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # List to store results\n",
    "        results = []\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face region\n",
    "            face_img = image[y:y+h, x:x+w]\n",
    "\n",
    "            try:\n",
    "                # Analyze face for emotion\n",
    "                analysis = DeepFace.analyze(\n",
    "                    face_img,\n",
    "                    actions=['emotion'],\n",
    "                    enforce_detection=False,\n",
    "                    silent=True\n",
    "                )\n",
    "\n",
    "                # Get the dominant emotion\n",
    "                emotion = analysis[0]['dominant_emotion']\n",
    "                emotion_scores = analysis[0]['emotion']\n",
    "\n",
    "                # Create result dictionary\n",
    "                result = {\n",
    "                    'location': (x, y, w, h),\n",
    "                    'emotion': emotion,\n",
    "                    'emotion_scores': emotion_scores\n",
    "                }\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "                # Draw rectangle around face\n",
    "                cv2.rectangle(processed_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "                # Display emotion\n",
    "                label = f\"{emotion}\"\n",
    "                cv2.putText(processed_image, label, (x, y-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing face: {str(e)}\")\n",
    "\n",
    "        return processed_image, results\n",
    "\n",
    "    def detect_from_image_path(self, image_path):\n",
    "        \"\"\"\n",
    "        Detect faces and emotions from an image file\n",
    "\n",
    "        Parameters:\n",
    "        - image_path: Path to image file\n",
    "        \n",
    "        Returns:\n",
    "        - results: List of dictionaries containing face locations and emotions\n",
    "        \"\"\"\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not read image from {image_path}\")\n",
    "            return None\n",
    "\n",
    "        # Process the image\n",
    "        processed_image, results = self.detect_faces_emotions(image)\n",
    "\n",
    "        # Display results\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Face & Emotion Detection Results\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # Print detailed results\n",
    "        print(f\"Detected {len(results)} faces:\")\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"Face {i+1}:\")\n",
    "            print(f\"  - Emotion: {result['emotion']}\")\n",
    "            print(\"  - Emotion scores:\")\n",
    "            for emotion, score in result['emotion_scores'].items():\n",
    "                print(f\"    - {emotion}: {score:.2f}%\")\n",
    "            print()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def detect_from_webcam(self, duration=30, display_type='window'):\n",
    "        \"\"\"\n",
    "        Detect faces and emotions from webcam feed\n",
    "\n",
    "        Parameters:\n",
    "        - duration: Duration in seconds to run detection\n",
    "        - display_type: 'window' for OpenCV window or 'matplotlib' for matplotlib display\n",
    "        \"\"\"\n",
    "        # Initialize webcam\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open webcam\")\n",
    "            return\n",
    "\n",
    "        print(f\"Running face and emotion detection for {duration} seconds...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if display_type == 'matplotlib':\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "        while time.time() - start_time < duration:\n",
    "            # Read frame from webcam\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame from webcam\")\n",
    "                break\n",
    "\n",
    "            # Process the frame\n",
    "            processed_frame, results = self.detect_faces_emotions(frame)\n",
    "\n",
    "            if display_type == 'window':\n",
    "                # Display using OpenCV window (better for VS Code)\n",
    "                cv2.imshow('Face & Emotion Detection', processed_frame)\n",
    "            else:\n",
    "                # Display using matplotlib\n",
    "                plt.clf()\n",
    "                plt.imshow(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB))\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"Face & Emotion Detection - Time remaining: {int(duration - (time.time() - start_time))}s\")\n",
    "                plt.pause(0.01)\n",
    "\n",
    "            # Print detection results\n",
    "            print(f\"\\rDetected {len(results)} faces. Dominant emotions: \" +\n",
    "                  \", \".join([f\"{i+1}: {r['emotion']}\" for i, r in enumerate(results)]), end=\"\")\n",
    "\n",
    "            # Check for quit key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release webcam and close windows\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if display_type == 'matplotlib':\n",
    "            plt.close()\n",
    "        print(\"\\nDetection complete\")\n",
    "\n",
    "    def browse_for_image(self):\n",
    "        \"\"\"\n",
    "        Open a file dialog to browse for an image file\n",
    "        \n",
    "        Returns:\n",
    "        - file_path: Path to the selected image file or None if canceled\n",
    "        \"\"\"\n",
    "        # Hide the main tkinter window\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        \n",
    "        # Open file dialog\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an image file\",\n",
    "            filetypes=[\n",
    "                (\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.gif\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Destroy the tkinter instance\n",
    "        root.destroy()\n",
    "        \n",
    "        return file_path if file_path else None\n",
    "\n",
    "    def save_processed_image(self, processed_image, original_path=None):\n",
    "        \"\"\"\n",
    "        Save the processed image with detection results\n",
    "        \n",
    "        Parameters:\n",
    "        - processed_image: Image with detection results\n",
    "        - original_path: Path of the original image to derive save location\n",
    "        \n",
    "        Returns:\n",
    "        - saved_path: Path where the image was saved\n",
    "        \"\"\"\n",
    "        if original_path:\n",
    "            # Derive output filename from input\n",
    "            filename, ext = os.path.splitext(original_path)\n",
    "            output_path = f\"{filename}_detected{ext}\"\n",
    "        else:\n",
    "            # Use default location with timestamp\n",
    "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            output_path = f\"detected_faces_{timestamp}.jpg\"\n",
    "            \n",
    "        # Save the image\n",
    "        cv2.imwrite(output_path, processed_image)\n",
    "        print(f\"Processed image saved to: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "# Check if running in Jupyter\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        get_ipython()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Function to demonstrate usage in Jupyter\n",
    "def run_jupyter_demo():\n",
    "    detector = FaceEmotionDetection()\n",
    "    \n",
    "    print(\"Face Emotion Detection Tool - Jupyter Mode\")\n",
    "    print(\"\\nChoose an option:\")\n",
    "    print(\"1. Run webcam detection\")\n",
    "    print(\"2. Select an image file\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "    \n",
    "    if choice == '1':\n",
    "        duration = input(\"Enter duration in seconds (default: 30): \")\n",
    "        duration = int(duration) if duration.isdigit() else 30\n",
    "        \n",
    "        # For Jupyter, use matplotlib display\n",
    "        detector.detect_from_webcam(duration=duration, display_type='matplotlib')\n",
    "    elif choice == '2':\n",
    "        image_path = detector.browse_for_image()\n",
    "        if image_path:\n",
    "            print(f\"Selected image: {image_path}\")\n",
    "            results = detector.detect_from_image_path(image_path)\n",
    "            \n",
    "            save_choice = input(\"Do you want to save the processed image? (y/n): \")\n",
    "            if save_choice.lower() == 'y':\n",
    "                # We need to reprocess the image to save it\n",
    "                image = cv2.imread(image_path)\n",
    "                processed_image, _ = detector.detect_faces_emotions(image)\n",
    "                detector.save_processed_image(processed_image, image_path)\n",
    "        else:\n",
    "            print(\"No image selected\")\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "\n",
    "# Function to run command line interface\n",
    "def run_command_line():\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Face and Emotion Detection Tool')\n",
    "    parser.add_argument('--image', help='Path to the image file')\n",
    "    parser.add_argument('--webcam', action='store_true', help='Use webcam for detection')\n",
    "    parser.add_argument('--duration', type=int, default=30, help='Duration for webcam detection in seconds')\n",
    "    parser.add_argument('--browse', action='store_true', help='Open file browser to select an image')\n",
    "    parser.add_argument('--save', action='store_true', help='Save the processed image with detection results')\n",
    "    \n",
    "    # Ignore unrecognized arguments (helps with Jupyter)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    # Initialize the detector\n",
    "    detector = FaceEmotionDetection()\n",
    "    \n",
    "    if args.webcam:\n",
    "        # Use webcam\n",
    "        detector.detect_from_webcam(duration=args.duration, display_type='window')\n",
    "    elif args.image:\n",
    "        # Use specified image path\n",
    "        image_path = args.image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            processed_image, results = detector.detect_faces_emotions(image)\n",
    "            \n",
    "            # Display the image\n",
    "            cv2.imshow('Face & Emotion Detection Results', processed_image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Save if requested\n",
    "            if args.save:\n",
    "                detector.save_processed_image(processed_image, image_path)\n",
    "                \n",
    "            # Print results\n",
    "            print(f\"Detected {len(results)} faces:\")\n",
    "            for i, result in enumerate(results):\n",
    "                print(f\"Face {i+1}:\")\n",
    "                print(f\"  - Emotion: {result['emotion']}\")\n",
    "                print(\"  - Emotion scores:\")\n",
    "                for emotion, score in result['emotion_scores'].items():\n",
    "                    print(f\"    - {emotion}: {score:.2f}%\")\n",
    "                print()\n",
    "        else:\n",
    "            print(f\"Error: Could not read image from {image_path}\")\n",
    "    elif args.browse:\n",
    "        # Open file browser to select image\n",
    "        image_path = detector.browse_for_image()\n",
    "        if image_path:\n",
    "            print(f\"Selected image: {image_path}\")\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                processed_image, results = detector.detect_faces_emotions(image)\n",
    "                \n",
    "                # Display the image\n",
    "                cv2.imshow('Face & Emotion Detection Results', processed_image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                # Save if requested\n",
    "                if args.save:\n",
    "                    detector.save_processed_image(processed_image, image_path)\n",
    "                    \n",
    "                # Print results\n",
    "                print(f\"Detected {len(results)} faces:\")\n",
    "                for i, result in enumerate(results):\n",
    "                    print(f\"Face {i+1}:\")\n",
    "                    print(f\"  - Emotion: {result['emotion']}\")\n",
    "                    print(\"  - Emotion scores:\")\n",
    "                    for emotion, score in result['emotion_scores'].items():\n",
    "                        print(f\"    - {emotion}: {score:.2f}%\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(f\"Error: Could not read image from {image_path}\")\n",
    "        else:\n",
    "            print(\"No image selected\")\n",
    "    else:\n",
    "        # No arguments provided, show usage instructions\n",
    "        print(\"Face & Emotion Detection Tool\")\n",
    "        print(\"\\nUsage options:\")\n",
    "        print(\"1. Run with webcam: python face_emotion_detector.py --webcam\")\n",
    "        print(\"2. Analyze image file: python face_emotion_detector.py --image path/to/image.jpg\")\n",
    "        print(\"3. Browse for image: python face_emotion_detector.py --browse\")\n",
    "        print(\"4. Save detection results: Add --save to any command\")\n",
    "        print(\"\\nFor more options, use: python face_emotion_detector.py --help\")\n",
    "\n",
    "# Main entry point\n",
    "if __name__ == \"__main__\":\n",
    "    if is_jupyter():\n",
    "        # Running in Jupyter, use interactive mode\n",
    "        run_jupyter_demo()\n",
    "    else:\n",
    "        # Running as a script, use command line mode\n",
    "        run_command_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb91ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "Loading face: Rahma\n",
      "Successfully loaded face for Rahma\n",
      "Loaded 1 known faces\n",
      "\n",
      "Attendance and Emotion Recognition System\n",
      "=========================================\n",
      "1. Add new face from webcam\n",
      "2. Add new face from image file\n",
      "3. Run attendance system (webcam)\n",
      "4. Process image for attendance\n",
      "5. Generate attendance reports\n",
      "6. Exit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from deepface import DeepFace  # For face and emotion detection\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk, filedialog, simpledialog, messagebox\n",
    "\n",
    "class AttendanceEmotionSystem:\n",
    "    def __init__(self, known_faces_dir=\"known_faces\", attendance_file=\"attendance_log.csv\"):\n",
    "        \"\"\"\n",
    "        Initialize the attendance and emotion monitoring system.\n",
    "\n",
    "        Parameters:\n",
    "        - known_faces_dir: Directory containing images of known individuals\n",
    "        - attendance_file: CSV file to store attendance records\n",
    "        \"\"\"\n",
    "        self.known_faces_dir = known_faces_dir\n",
    "        self.attendance_file = attendance_file\n",
    "        self.known_face_names = []\n",
    "        self.emotions = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "\n",
    "        # Ensure directories exist\n",
    "        if not os.path.exists(known_faces_dir):\n",
    "            os.makedirs(known_faces_dir)\n",
    "            print(f\"Created directory for known faces: {known_faces_dir}\")\n",
    "\n",
    "        # Initialize face detection and recognition\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # Initialize attendance log file if it doesn't exist\n",
    "        if not os.path.exists(attendance_file):\n",
    "            self._create_attendance_file()\n",
    "\n",
    "        # Load known faces\n",
    "        self._load_known_faces()\n",
    "\n",
    "    def _create_attendance_file(self):\n",
    "        \"\"\"Create a new attendance log file with appropriate headers.\"\"\"\n",
    "        df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\", \"Emotion\"])\n",
    "        df.to_csv(self.attendance_file, index=False)\n",
    "        print(f\"Created attendance log file: {self.attendance_file}\")\n",
    "\n",
    "    def _load_known_faces(self):\n",
    "        \"\"\"Load all known faces from the directory.\"\"\"\n",
    "        print(\"Loading known faces...\")\n",
    "        if not os.path.exists(self.known_faces_dir):\n",
    "            print(f\"Warning: Known faces directory '{self.known_faces_dir}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        for filename in os.listdir(self.known_faces_dir):\n",
    "            if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                print(f\"Loading face: {name}\")\n",
    "                self.known_face_names.append(name)\n",
    "                print(f\"Successfully loaded face for {name}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.known_face_names)} known faces\")\n",
    "\n",
    "    def browse_for_image(self, title=\"Select an image\"):\n",
    "        \"\"\"Open a file dialog to browse for an image file.\"\"\"\n",
    "        root = Tk()\n",
    "        root.withdraw()  # Hide the main window\n",
    "        \n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=title,\n",
    "            filetypes=[\n",
    "                (\"Image files\", \"*.jpg *.jpeg *.png *.bmp\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "        root.destroy()\n",
    "        return file_path if file_path else None\n",
    "\n",
    "    def add_new_face_from_file(self):\n",
    "        \"\"\"Add a new face from an image file selected via dialog.\"\"\"\n",
    "        # Get name for the person\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        name = simpledialog.askstring(\"Input\", \"Enter name for the person:\")\n",
    "        root.destroy()\n",
    "        \n",
    "        if not name:\n",
    "            print(\"Operation cancelled\")\n",
    "            return\n",
    "            \n",
    "        # Select image file\n",
    "        image_path = self.browse_for_image(f\"Select image for {name}\")\n",
    "        \n",
    "        if not image_path:\n",
    "            print(\"No image selected, operation cancelled\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Read the image\n",
    "            frame = cv2.imread(image_path)\n",
    "            if frame is None:\n",
    "                print(f\"Failed to read image from {image_path}\")\n",
    "                return\n",
    "                \n",
    "            # Save the image to known faces directory\n",
    "            img_path = os.path.join(self.known_faces_dir, f\"{name}.jpg\")\n",
    "            cv2.imwrite(img_path, frame)\n",
    "            print(f\"Face saved as {img_path}\")\n",
    "            \n",
    "            # Add to known faces\n",
    "            self.known_face_names.append(name)\n",
    "            print(f\"Added {name} to known faces\")\n",
    "            \n",
    "            # Show confirmation\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showinfo(\"Success\", f\"Successfully added {name} to known faces.\")\n",
    "            root.destroy()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding face: {str(e)}\")\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showerror(\"Error\", f\"Failed to add face: {str(e)}\")\n",
    "            root.destroy()\n",
    "\n",
    "    def add_new_face_from_webcam(self):\n",
    "        \"\"\"Capture and add a new face from webcam.\"\"\"\n",
    "        # Get name for the person\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        name = simpledialog.askstring(\"Input\", \"Enter name for the person:\")\n",
    "        root.destroy()\n",
    "        \n",
    "        if not name:\n",
    "            print(\"Operation cancelled\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Initialize webcam\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if not cap.isOpened():\n",
    "                print(\"Error: Could not open webcam\")\n",
    "                return\n",
    "                \n",
    "            print(\"Preparing to capture face. Please look at the camera...\")\n",
    "            \n",
    "            # Create window for preview\n",
    "            cv2.namedWindow(\"Capture Face\", cv2.WINDOW_NORMAL)\n",
    "            \n",
    "            # Countdown display\n",
    "            for i in range(3, 0, -1):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Failed to capture frame\")\n",
    "                    break\n",
    "                    \n",
    "                # Display countdown\n",
    "                cv2.putText(frame, f\"Capturing in {i}...\", (30, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "                cv2.imshow(\"Capture Face\", frame)\n",
    "                cv2.waitKey(1000)  # Wait for 1 second\n",
    "            \n",
    "            # Capture the frame\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Display \"Captured!\" message\n",
    "                cv2.putText(frame, \"Captured!\", (30, 60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
    "                cv2.imshow(\"Capture Face\", frame)\n",
    "                cv2.waitKey(1000)  # Show the captured frame for 1 second\n",
    "                \n",
    "                # Save the image\n",
    "                img_path = os.path.join(self.known_faces_dir, f\"{name}.jpg\")\n",
    "                cv2.imwrite(img_path, frame)\n",
    "                print(f\"Face captured and saved as {img_path}\")\n",
    "                \n",
    "                # Add to known faces\n",
    "                self.known_face_names.append(name)\n",
    "                print(f\"Added {name} to known faces\")\n",
    "                \n",
    "                # Show confirmation\n",
    "                root = Tk()\n",
    "                root.withdraw()\n",
    "                messagebox.showinfo(\"Success\", f\"Successfully added {name} to known faces.\")\n",
    "                root.destroy()\n",
    "                \n",
    "            else:\n",
    "                print(\"Failed to capture image\")\n",
    "                \n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding face: {str(e)}\")\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showerror(\"Error\", f\"Failed to add face: {str(e)}\")\n",
    "            root.destroy()\n",
    "\n",
    "    def mark_attendance(self, name, emotion):\n",
    "        \"\"\"\n",
    "        Mark attendance for a recognized face.\n",
    "\n",
    "        Parameters:\n",
    "        - name: Name of the recognized person\n",
    "        - emotion: Detected emotion\n",
    "        \"\"\"\n",
    "        now = datetime.datetime.now()\n",
    "        date_str = now.strftime(\"%Y-%m-%d\")\n",
    "        time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # Check if attendance already marked for today\n",
    "        df = pd.read_csv(self.attendance_file)\n",
    "        today_records = df[(df[\"Name\"] == name) & (df[\"Date\"] == date_str)]\n",
    "\n",
    "        if today_records.empty:\n",
    "            new_record = pd.DataFrame({\"Name\": [name],\n",
    "                                      \"Date\": [date_str],\n",
    "                                      \"Time\": [time_str],\n",
    "                                      \"Emotion\": [emotion]})\n",
    "\n",
    "            df = pd.concat([df, new_record], ignore_index=True)\n",
    "            df.to_csv(self.attendance_file, index=False)\n",
    "            return True, f\"Marked attendance for {name}\"\n",
    "        else:\n",
    "            return False, f\"{name} already marked for today\"\n",
    "\n",
    "    def recognize_face(self, frame):\n",
    "        \"\"\"\n",
    "        Recognize a face in the given frame using DeepFace.\n",
    "\n",
    "        Parameters:\n",
    "        - frame: Image frame to analyze\n",
    "\n",
    "        Returns:\n",
    "        - name: Name of the recognized person or \"Unknown\"\n",
    "        - emotion: Detected emotion\n",
    "        - face_location: Location of the detected face\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "\n",
    "            try:\n",
    "                # Analyze face for emotion\n",
    "                result = DeepFace.analyze(face_img, actions=['emotion'], enforce_detection=False, silent=True)\n",
    "\n",
    "                emotion = result[0]['dominant_emotion']\n",
    "\n",
    "                # Try to recognize the face\n",
    "                name = \"Unknown\"\n",
    "                if self.known_face_names:  # Only try recognition if we have known faces\n",
    "                    try:\n",
    "                        recognition = DeepFace.find(face_img, self.known_faces_dir, enforce_detection=False, silent=True)\n",
    "                        if not recognition[0].empty:\n",
    "                            # Extract the name from the path\n",
    "                            identity_path = recognition[0].iloc[0]['identity']\n",
    "                            name = os.path.splitext(os.path.basename(identity_path))[0]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                return name, emotion, (x, y, w, h)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return None, None, None\n",
    "\n",
    "    def process_image_file(self):\n",
    "        \"\"\"Process a single image file for attendance.\"\"\"\n",
    "        # Select image file\n",
    "        image_path = self.browse_for_image(\"Select image for attendance\")\n",
    "        \n",
    "        if not image_path:\n",
    "            print(\"No image selected\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Read the image\n",
    "            frame = cv2.imread(image_path)\n",
    "            if frame is None:\n",
    "                print(f\"Failed to read image from {image_path}\")\n",
    "                return\n",
    "                \n",
    "            # Create a copy for displaying results\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Detect and recognize faces\n",
    "            marked_attendance = set()\n",
    "            \n",
    "            name, emotion, face_location = self.recognize_face(frame)\n",
    "            \n",
    "            if name and face_location:\n",
    "                x, y, w, h = face_location\n",
    "                \n",
    "                # Draw rectangle around face\n",
    "                cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Display name and emotion\n",
    "                label = f\"{name} - {emotion}\"\n",
    "                cv2.putText(display_frame, label, (x, y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "                # Mark attendance if not already marked\n",
    "                if name != \"Unknown\":\n",
    "                    success, message = self.mark_attendance(name, emotion)\n",
    "                    if success:\n",
    "                        marked_attendance.add(name)\n",
    "                    print(message)\n",
    "                    \n",
    "                    # Add status text to image\n",
    "                    cv2.putText(display_frame, message, (10, 30), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow(\"Attendance Processing Result\", display_frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Show summary\n",
    "            if marked_attendance:\n",
    "                message = f\"Marked attendance for: {', '.join(marked_attendance)}\"\n",
    "            else:\n",
    "                message = \"No attendance marked\"\n",
    "                \n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showinfo(\"Attendance Result\", message)\n",
    "            root.destroy()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {str(e)}\")\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showerror(\"Error\", f\"Failed to process image: {str(e)}\")\n",
    "            root.destroy()\n",
    "\n",
    "    def run_attendance_system(self, duration=30):\n",
    "        \"\"\"\n",
    "        Run the attendance system for a specified duration using webcam.\n",
    "\n",
    "        Parameters:\n",
    "        - duration: Number of seconds to run the system\n",
    "        \"\"\"\n",
    "        # Initialize webcam\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open webcam\")\n",
    "            return\n",
    "            \n",
    "        start_time = time.time()\n",
    "        marked_attendance = set()\n",
    "        \n",
    "        # Create window for display\n",
    "        cv2.namedWindow(\"Attendance System\", cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        while time.time() - start_time < duration:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame\")\n",
    "                break\n",
    "                \n",
    "            # Create a copy for displaying results\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Display time remaining\n",
    "            time_remaining = int(duration - (time.time() - start_time))\n",
    "            cv2.putText(display_frame, f\"Time remaining: {time_remaining}s\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            # Detect and recognize faces\n",
    "            name, emotion, face_location = self.recognize_face(frame)\n",
    "            \n",
    "            if name and face_location:\n",
    "                x, y, w, h = face_location\n",
    "                \n",
    "                # Draw rectangle around face\n",
    "                cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Display name and emotion\n",
    "                label = f\"{name} - {emotion}\"\n",
    "                cv2.putText(display_frame, label, (x, y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "                # Mark attendance if not already marked\n",
    "                if name != \"Unknown\" and name not in marked_attendance:\n",
    "                    success, message = self.mark_attendance(name, emotion)\n",
    "                    if success:\n",
    "                        marked_attendance.add(name)\n",
    "                    \n",
    "                    # Display message on frame\n",
    "                    cv2.putText(display_frame, message, (10, 60), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    print(message)\n",
    "            \n",
    "            # Display the frame\n",
    "            cv2.imshow(\"Attendance System\", display_frame)\n",
    "            \n",
    "            # Check for quit key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Show summary\n",
    "        print(\"\\nAttendance Summary:\")\n",
    "        print(f\"Total people recognized: {len(marked_attendance)}\")\n",
    "        print(f\"People recognized: {', '.join(marked_attendance) if marked_attendance else 'None'}\")\n",
    "        \n",
    "        if marked_attendance:\n",
    "            message = f\"Marked attendance for: {', '.join(marked_attendance)}\"\n",
    "        else:\n",
    "            message = \"No attendance marked\"\n",
    "            \n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        messagebox.showinfo(\"Attendance Summary\", message)\n",
    "        root.destroy()\n",
    "\n",
    "    def generate_reports(self):\n",
    "        \"\"\"Generate reports from the attendance data.\"\"\"\n",
    "        if not os.path.exists(self.attendance_file):\n",
    "            print(\"No attendance data available\")\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showinfo(\"Report\", \"No attendance data available\")\n",
    "            root.destroy()\n",
    "            return\n",
    "\n",
    "        df = pd.read_csv(self.attendance_file)\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"No attendance records found\")\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            messagebox.showinfo(\"Report\", \"No attendance records found\")\n",
    "            root.destroy()\n",
    "            return\n",
    "\n",
    "        # Create report text\n",
    "        report_text = \"===== ATTENDANCE REPORT =====\\n\\n\"\n",
    "        \n",
    "        # Daily attendance report\n",
    "        report_text += \"=== Daily Attendance Report ===\\n\"\n",
    "        daily_count = df.groupby('Date').size()\n",
    "        report_text += daily_count.to_string() + \"\\n\\n\"\n",
    "\n",
    "        # Person-wise report\n",
    "        report_text += \"=== Person-wise Attendance Report ===\\n\"\n",
    "        person_count = df.groupby('Name').size()\n",
    "        report_text += person_count.to_string() + \"\\n\\n\"\n",
    "\n",
    "        # Emotion analysis\n",
    "        report_text += \"=== Emotion Analysis ===\\n\"\n",
    "        emotion_count = df.groupby('Emotion').size()\n",
    "        report_text += emotion_count.to_string() + \"\\n\"\n",
    "\n",
    "        # Print to console\n",
    "        print(report_text)\n",
    "        \n",
    "        # Display in message box\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        messagebox.showinfo(\"Attendance Report\", report_text)\n",
    "        root.destroy()\n",
    "\n",
    "        # Visualize emotion distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        emotion_count.plot(kind='bar', color='skyblue')\n",
    "        plt.title('Emotion Distribution')\n",
    "        plt.xlabel('Emotion')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def display_menu():\n",
    "    \"\"\"Display main menu options.\"\"\"\n",
    "    print(\"\\nAttendance and Emotion Recognition System\")\n",
    "    print(\"=========================================\")\n",
    "    print(\"1. Add new face from webcam\")\n",
    "    print(\"2. Add new face from image file\")\n",
    "    print(\"3. Run attendance system (webcam)\")\n",
    "    print(\"4. Process image for attendance\")\n",
    "    print(\"5. Generate attendance reports\")\n",
    "    print(\"6. Exit\")\n",
    "    choice = input(\"\\nEnter your choice (1-6): \")\n",
    "    return choice\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the application.\"\"\"\n",
    "    system = AttendanceEmotionSystem()\n",
    "    \n",
    "    while True:\n",
    "        choice = display_menu()\n",
    "        \n",
    "        if choice == '1':\n",
    "            system.add_new_face_from_webcam()\n",
    "        elif choice == '2':\n",
    "            system.add_new_face_from_file()\n",
    "        elif choice == '3':\n",
    "            duration = input(\"Enter duration in seconds (default: 30): \")\n",
    "            duration = int(duration) if duration.strip().isdigit() else 30\n",
    "            system.run_attendance_system(duration=duration)\n",
    "        elif choice == '4':\n",
    "            system.process_image_file()\n",
    "        elif choice == '5':\n",
    "            system.generate_reports()\n",
    "        elif choice == '6':\n",
    "            print(\"Exiting application.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44ac90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pygame in c:\\users\\cyber-tech\\appdata\\roaming\\python\\python312\\site-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
